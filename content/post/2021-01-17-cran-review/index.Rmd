---
title: CRAN review
author: Llu√≠s Revilla Sancho
date: '2021-01-17'
categories:
  - r
  - CRAN
tags:
  - CRAN
  - R
  - reviews
slug: CRAN-review
editor_options:
  chunk_output_type: console
featured: no
draft: false
image:
  caption: ''
  focal_point: ''
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

[cransays](https://github.com/lockedata/cransays) is a package to check package submissions which on the online documentation provides a [dashboard which](https://lockedata.github.io/cransays/articles/dashboard.html) is updated each hour.
At the same time recently (since 2020/09/12) the status of the queues and folders of submissions are stored. 
Using this information and the recent [script provided by Tim Taylor](https://github.com/tjtnew/newbies) I'll check how are the submissions on CRAN. 

```{r prepare, eval = FALSE}
# Downloading the cransays repository branch history
download.file("https://github.com/lockedata/cransays/archive/history.zip", 
              destfile = "static/cransays-history.zip")
path_zip <- here::here("static", "cransays-history.zip") 
# We unzip the files to read them
dat <- unzip(path_zip, exdir = "static")
csv <- dat[grepl("*.csv$", x = dat)]
dates <- gsub("cran-incoming-(.+)\\.csv", "\\1", basename(csv))
date_cransays <- as.POSIXct(dates, format = "%Y%m%dT%H%M", tz = "UTC")
f <- sapply(csv, read.csv)
m <- function(x, y) {
  merge(x, y, sort = FALSE, all = TRUE)
}
updates <- Reduce(m, f) # Merge all files
write.csv(updates, file = "static/cran_till_now.csv",  row.names = FALSE)
# Clean up
unlink("static/cransays-history/", recursive = TRUE)
unlink("static/cransays-history/", recursive = TRUE)
unlink("static/cransays-history.zip", recursive = TRUE)
```

After preparing the files in one big file we can load and work with it.

```{r load}
path_file <- here::here("static", "post", "2020-01-cran-dependencies_files", 
                        "cran_till_now.csv")
cran_submissions <- read.csv(path_file)
col_names <- c("package", "version", "snapshot_time", "folder", "subfolder")
cran_submissions <- cran_submissions[, col_names]
library("tidyverse")
theme_set(theme_minimal())
library("lubridate")
cran_submissions$snapshot_time <- as.POSIXct(cran_submissions$snapshot_time,
                                             tz = "UTC")
```


## CRAN load

We all know that CRAN is busy with updates, reports of bug fixes and so on.
Thanks to cransays now we can see how much have the reviewers of CRAN on their plates.

The period we are going to analyze is from the beginning of the records till 2021/01/02.
It includes some well earned holiday time for the CRAN team, during which submissions are not possible.

I've read some comments on the inconsistencies of where do the holidays of the CRAN teams are reported and for the short period of time  so far by cransays I used a [screenshot](https://twitter.com/krlmlr/status/1346005787668336640) found on twitter.

```{r cran-holidays}
holidays <- data.frame(
  start = as.POSIXct("18/12/2020", format = "%d/%m/%Y", tz = "UTC"), 
  end = as.POSIXct("04/01/2021", format = "%d/%m/%Y", tz = "UTC")
)
```


```{r cran-queues}
cran_submissions <- cran_submissions[!is.na(cran_submissions$version), ]
cran_queue <- cran_submissions %>% 
  group_by(snapshot_time) %>% 
  summarize(n = n_distinct(package))
ggplot(cran_queue) +
  geom_rect(data = holidays, aes(xmin = start, xmax = end, ymin = 0, ymax = 200),
            alpha = 0.5, fill = "red") +
  annotate("text", x = holidays$start + (holidays$end - holidays$start)/2, 
           y = 150, label = "CRAN holidays") +
  geom_path(aes(snapshot_time, n)) +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
                   expand = expansion()) +
  scale_y_continuous(expand = expansion()) +
  labs(x = element_blank(), y = element_blank(), 
       title = "Packages on CRAN review process")
```

We can see that there are some ups and downs, but no specially increase before the holidays.
There are some instance were the number of package on the queue have a sudden drop and then a recovery to previous levels. 
This might be an error on the CRAN system, or the cransays' script. 

We can also see that people do not tend to rush and push the package before the holidays.

And the increase of package submissions after they start accepting packages again?


I do not have a clear understanding of the CRAN review process, but it seems like classifying to folders is part of the way to signal in which part of the process they are:

```{r cran-submissions}
man_colors <- RColorBrewer::brewer.pal(8, "Dark2")
names(man_colors) <- unique(cran_submissions$folder)
cran_submissions %>% 
  group_by(folder, snapshot_time) %>% 
  summarize(packages = n_distinct(package)) %>% 
  ggplot() +
  geom_rect(data = holidays, aes(xmin = start, xmax = end, ymin = 0, ymax = 150),
            alpha = 0.25, fill = "red") +
  annotate("text", x = holidays$start + (holidays$end - holidays$start)/2, 
           y = 75, label = "CRAN holidays") +
  geom_path(aes(snapshot_time, packages, col = folder)) +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
                   expand = expansion()) +
  scale_y_continuous(expand = expansion()) +
  scale_color_manual(values = man_colors) +
  labs(x = element_blank(), y = element_blank(),
       title = "Packages by folder", col = "Folder")
```

The queue trend is mostly driven by newbies folder.
Surprisingly when the queue is split by folder we don't see those sudden drops.
This might indicate that there is a clean up on some of the folders.
What we clearly see is a clean up on holidays, when almost all was cleared up.

<details>
<summary>Detail on just the holidays dates</summary>

```{r cran-holidays-zoom}
cran_submissions %>% 
  group_by(folder, snapshot_time) %>% 
  summarize(packages = n_distinct(package)) %>% 
  filter(snapshot_time >= holidays$start & snapshot_time <= holidays$end) %>% 
  ggplot() +
  geom_path(aes(snapshot_time, packages, col = folder)) +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "1 day", 
                   expand = expansion()) +
  scale_y_continuous(expand = expansion(), limits = c(0, NA)) +
  scale_color_manual(values = man_colors) +
  labs(x = element_blank(), y = element_blank(),
       title = "Holidays", col = "Folder") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = c(0.5, 0.6))
```

It seems like that on the 31st there was a clean up of some packages on the waiting list.

</details>

## Time patterns

We can look for patterns on the queue:
 - Month
 - [Day of the month](#day-month)
 - [Day of the week](#day-week)
 
### By day of the month {day-month}

```{r cran-monthly}
cran_times <- cran_submissions %>% 
  mutate(seconds = seconds(snapshot_time),
         month = month(snapshot_time),
         mday = mday(snapshot_time),
         wday = wday(snapshot_time, locale = "en_GB.UTF-8"),
         week = week(snapshot_time),
         date = as_date(snapshot_time),
         submission = paste(package, version, sep = "-"))
cran_times %>% 
  arrange(folder, date, mday) %>% 
  group_by(folder, date, mday) %>% 
  summarize(packages = n_distinct(package),
            week = unique(week)) %>% 
  group_by(folder, mday) %>% 
  ggplot() +
  # geom_point(aes(mday, packages, col = fct_reorder2(folder, mday, packages, sum))) +
  geom_smooth(aes(mday, packages, col = folder)) +
  labs(x = "Day of the month", y = element_blank(), col = "Folder",
       title = "Evolution by month day") +
  scale_color_manual(values = man_colors) +
  coord_cartesian(ylim = c(0, NA), xlim = c(1, NA)) +
  scale_x_continuous(expand = expansion()) +
  scale_y_continuous(expand = expansion()) 
```

Surprisingly at the end of the month there is a big increase on package submissions and a decline on the packages on pretest.

### By day of the week

Do developers submit more on weekends or in work days?

```{r cran-wday}
cran_times %>% 
  group_by(folder, date, wday) %>% 
  summarize(packages = n_distinct(package),
            week = unique(week)) %>% 
  group_by(folder, wday) %>% 
  ggplot() +
  # geom_point(aes(wday, packages, col = fct_reorder2(folder, wday, packages, sum))) +
  geom_smooth(aes(wday, packages, col = folder)) +
  labs(x = "Day of the week", y = "Packages", col = "Folder",
       title = "Evolution by week day") +
  scale_color_manual(values = man_colors) +
  scale_x_continuous(breaks = 1:7, expand = expansion()) +
  scale_y_continuous(expand = expansion(), limits = c(0, NA))
```

It doesn't seem to be a special pattern only on the human folder there is an increase on weekdays and a decrease on the weekend. 
However, note that reviewers might be on multiple time zones and this doesn't allow us to make hard conclusions on this data. 

## Subfolder

There is also a subfolder:

```{r folder-subfolder}
cran_times %>% 
  mutate(subfolder = case_when(subfolder == "" ~ NA_character_,
                               TRUE ~ subfolder)) %>% 
  group_by(folder, subfolder) %>% 
  summarize(n = n()) %>% 
  ggplot() +
  geom_tile(aes(folder, subfolder, fill = n)) +
  scale_fill_continuous(trans = "log10") +
  scale_x_discrete(expand = expansion()) +
  scale_y_discrete(expand = expansion()) +
  labs(title = "Folders and subfolders", fill = "Packages",
       x = "Folder", y = "Subfolder") +
  theme(legend.position = c(0.9, 0.4))
```

We see that some packages are on the human folder but not under any of the other packages. 

```{r subfolder-pattern}
cran_members <- c("LH", "UL", "GS", "JH")
cran_times %>% 
  filter(subfolder %in% cran_members) %>% 
  group_by(subfolder, snapshot_time) %>% 
  summarize(packages = n_distinct(package)) %>% 
  ggplot() +
  geom_smooth(aes(snapshot_time, packages, col = subfolder)) +
    labs(x = element_blank(), y = element_blank(), col = "Subfolder",
       title = "Packages on subfolers") +
  scale_y_continuous(expand = expansion(), breaks = 0:10) +
  coord_cartesian(y = c(0, NA))  +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
               expand = expansion(add = 2))
```

```{r subfolder-mday}
cran_times %>% 
  filter(subfolder %in% cran_members) %>% 
  group_by(subfolder, mday) %>% 
  summarize(packages = n_distinct(package)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_smooth(aes(mday, packages, col = subfolder)) +
  labs(x = "Day of the month", y = element_blank(), col = "Subfolder",
       title = "Packages on subfolers by day of the month") +
  scale_y_continuous(expand = expansion()) +
  scale_x_continuous(expand = expansion(), breaks = c(1,7,14,21,29)) +
  coord_cartesian(ylim = c(0, NA))
```


```{r subfolder-wday, warning=FALSE}
cran_times %>% 
  filter(subfolder %in% cran_members) %>% 
  group_by(subfolder, wday) %>% 
  summarize(packages = n_distinct(package)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_smooth(aes(wday, packages, col = subfolder)) +
  labs(x = "Day of the week", y = element_blank(), col = "Subfolder",
       title = "Evolution by week day") +
  scale_y_continuous(expand = expansion()) +
  scale_x_continuous(breaks = 1:7, expand = expansion()) +
  coord_cartesian(ylim =  c(0, NA))
```

There seem to be only 2 people usually working with subfolders. 
Suppose that there aren't a common set of rules the reviewers follow.

## Information for sumbitters

From the developers and maintainers, one big question is when I submit when will be my package available on CRAN?
We can measure the time spend on the queue

```{r time-submission}
subm <- cran_times %>%
  group_by(submission) %>% 
  arrange(snapshot_time) %>% 
  select(package, version, submission, snapshot_time) %>% 
  filter(row_number() %in% c(1, last(row_number()))) %>% 
  arrange(submission)
```

There are `r sum(table(subm$package) == 1)` packages that are only seen once.
It might mean that it is an abandoned/rejected submissions like [knitcitations](https://github.com/cboettig/knitcitations/issues/107#issuecomment-736069214), other might be acceptances in less than an hour. `

```{r resubm}
rsubm <- subm %>% 
  filter(n_distinct(snapshot_time) == 2) %>%
  mutate(time = c("start", "end")) %>% 
  pivot_wider(values_from = snapshot_time, names_from = time) %>% 
  ungroup() %>% 
  mutate(r = row_number(), 
         time  =  round(difftime(end, start, units = "hour"), 0)) %>% 
  group_by(package) %>% 
  mutate(n_submission = 1:n()) %>% 
  ungroup()
ggplot(rsubm) +
  geom_linerange(aes(y = fct_reorder(package, start, .fun = min, .desc = FALSE),
                      x = start, xmin = start, xmax = end, 
                     col = as.factor(n_submission))) + 
  labs(x = element_blank(), y = element_blank(), title = 
         "Packages on the queue", col = "Submissions") +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
                   expand = expansion(add = 2)) +
  scale_colour_viridis_d() +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_blank(),
        legend.position = c(0.15, 0.7))
```

We can see the rapid growth of packages and that on this period some people submitted up to 8 times their packages.

Also note that the definition used for submission is a package with different version number. 
Some authors do change the version number when CRAN reviewers require changes before accepting the package on CRAN while others do not and only change the version number according to their release cycle. 

Perhaps we could differentiate this by looking at the period between submissions but I think it won't be interesting.

Despite this differences we can see that most submissions are accepted fairly fast:

```{r package-time-queue}
rsubm %>% 
  group_by(package) %>% 
  summarize(time = sum(time)) %>% 
  ggplot() +
  geom_histogram(aes(time), bins = 100) +
  labs(title = "Packages total time on queue", x = "Hours", 
       y = element_blank()) +
  scale_x_continuous(expand = expansion()) +
  scale_y_continuous(expand = expansion())
```

Also note that I found some packages that remained on the submission queue, and thus picked up by cransays, even after acceptance. 


```{r submission-queue}
rsubm %>% 
  group_by(submission) %>% 
  summarize(time = sum(time)) %>% 
  ggplot() +
  geom_histogram(aes(time), bins = 100) +
  labs(title = "Submission time on queue", x = "Hours", 
       y = element_blank()) +
  scale_x_continuous(expand = expansion()) +
  scale_y_continuous(expand = expansion())
```

By submission many more are shortly spanned.
Perhaps hinting that more testing should be done before or what to expect on the review should be more clear to the authors, or that they are approved very fast. 

```{r time-submission-folder}
subm2 <- cran_times %>%
  group_by(submission, folder) %>% 
  arrange(snapshot_time) %>% 
  select(package, version, submission, snapshot_time, folder) %>% 
  filter(row_number() %in% c(1, last(row_number()))) %>% 
  arrange(submission)
```

There are `r sum(table(subm$package) == 1)` packages that are only seen once.
It might mean that it is an abandoned/rejected submissions like [knitcitations](https://github.com/cboettig/knitcitations/issues/107#issuecomment-736069214), other might be acceptances in less than an hour (I'll talk more about this later). 

```{r resubm2}
rsubm2 <- subm2 %>% 
  filter(n_distinct(snapshot_time) == 2) %>%
  mutate(time = c("start", "end")) %>% 
  pivot_wider(values_from = snapshot_time, names_from = time) %>% 
  ungroup() %>% 
  mutate(r = row_number(), 
         time  =  round(difftime(end, start, units = "hour"), 0)) %>% 
  group_by(package) %>% 
  mutate(n_submission = 1:n())
ggplot(rsubm2) +
  geom_linerange(aes(y = fct_reorder(package, start, .fun = min, .desc = FALSE),
                      x = start, xmin = start, xmax = end, col = folder)) + 
  labs(x = element_blank(), y = element_blank(), title = 
         "Packages on the queue") +
  scale_color_manual(values = man_colors) +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
               expand = expansion(add = 2)) +
  labs(col = "Folder") +
  theme_minimal() +
  theme(panel.grid.major.y = element_blank(),
        axis.text.y = element_blank(),
        legend.position = c(0.2, 0.7))
```

```{r submissions-n-folders}
rsubm2 %>% 
  group_by(submission) %>% 
  summarize(n_folder = n_distinct(folder)) %>% 
  ggplot() + 
  geom_histogram(aes(n_folder)) +
  labs(title = "Folders by submission", x = element_blank(), 
       y = element_blank())
```

Most submissions are only in one folder, but some go up to 5 folders.

```{r submissions-folders}
subm_folder <- rsubm2 %>% 
  group_by(submission) %>% 
  arrange(start) %>% 
  summarise(folder = list(folder)) %>% 
  count(folder, sort = TRUE)
```

The most 5 common folders process of submissions are `r paste(unlist(lapply(subm_folder$folder[1:5], paste, collapse = ", ")), collapse = "; ")`.

Another way of seeing if it is a right moment aside of how many packages are on the queue is looking how much activity there is:


```{r cran-pressure}
subm3 <- cran_times %>%
  arrange(snapshot_time) %>% 
  group_by(package) %>% 
  mutate(autor_change = submission != lag(submission),
         cran_change = folder != lag(folder)) %>% 
  mutate(autor_change = ifelse(is.na(autor_change), TRUE, autor_change),
         cran_change = ifelse(is.na(cran_change), FALSE, cran_change)) %>% 
  mutate(cran_change = case_when(subfolder != lag(subfolder) ~ TRUE,
                                 TRUE ~ cran_change)) %>% 
  ungroup()
subm3 %>% 
  group_by(snapshot_time) %>% 
  summarize(autor_change = sum(autor_change), cran_change = sum(cran_change)) %>% 
  filter(row_number() != 1) %>% 
  filter(autor_change != 0 | cran_change != 0) %>% 
  ggplot() +
  geom_point(aes(snapshot_time, autor_change), fill = "blue", size = 0) +
  geom_area(aes(snapshot_time, autor_change), fill = "blue") +
  geom_point(aes(snapshot_time, -cran_change), fill = "red", size = 0) +
  geom_area(aes(snapshot_time, -cran_change), fill = "red") +
  scale_x_datetime(date_labels = "%Y/%m/%d", date_breaks = "2 weeks", 
                   expand = expansion(add = 2)) +
  scale_y_continuous(expand = expansion(add = c(0, 0))) + 
  coord_cartesian(ylim = c(-26, 26)) +
  annotate("text", label = "CRAN's", y = 20, x = as_datetime("2020/11/02")) +
  annotate("text", label = "Author's", y = -20, x = as_datetime("2020/11/02")) +
  labs(y = "Changes", x = element_blank(), title = "Activity on CRAN:")
```

Only on few moments does the big pressure of the changes by authors as seen on the first plot. 

# Review process

There is a [scheme](https://lockedata.github.io/cransays/articles/dashboard.html#cran-review-workflow) about how does the review process work.
However, it has been pointed out that it needs an update.

We've seen which folders go before which ones, but we haven't looked up what is the last folder in which package appear:

```{r review-process}
last_seen <- cran_times %>% 
  ungroup() %>% 
  group_by(submission) %>% 
  arrange(snapshot_time) %>% 
  filter(1:n() == last(n())) %>% 
  ungroup()
count(last_seen, folder, sort = TRUE) %>% 
  knitr::kable()
```

We can see that many submissions were left at the pretest, and just a minority on the human or publish folders. 

# Github action reliability

The data of this post was collected using Github actions by cransays.
At the same time I set up a [bot/package](https://llrs.github.io/cranis/) to scan all the available packages on Bioconductor and CRAN, to track those packages that are accepted and when.
I left it running for 3 months without checking that I could recover the data.
When I started writing this post I found the data is not usable on the current format.

Instead together with the cransays data I'll use it to test how reliable are GitHub actions are.


```{r gha, eval=FALSE}
download.file("https://github.com/llrs/cranis/archive/history.zip",
              destfile = "static/cranis-history.zip")
path_zip <- here::here("static", "cranis-history.zip") # From downloading the cransays repository branch history
dat <- unzip(path_zip, list = TRUE)
csv <- dat$Name[grepl("*.csv$", x = dat$Name)]
dates <- gsub("available-packages-(.+)\\.csv", "\\1", basename(csv))
date <- as.POSIXct(dates, format = "%Y%m%dT%H%M", "UTC")
gha <- data.frame(
  month = month(date), 
  mday = mday(date), 
  wday = wday(date), 
  week = week(date),
  minute = minute(date), 
  hour = hour(date), 
  type = "cranis")
```

For now, however we will use the data we already have

```{r gha2}
gha <- cbind(cran_times[, c("month", "mday", "wday", "week")], 
      minute = minute(cran_submissions$snapshot_time), 
      hour = hour(cran_times$snapshot_time),
      type = "cransays") %>% 
  distinct()
gha %>% 
  ggplot() +
  geom_violin(aes(as.factor(hour), minute)) +
  scale_y_continuous(expand = expansion(add = 0.5), 
                     breaks = c(0, 15, 30, 45, 60), limits = c(0, 60)) +
  scale_x_discrete(expand = expansion())  +
  labs(x = "Hour", y = "Minute", title = "Daily variation")
```

There seems to be a lower limit around 10 minutes except for some builds that I think were manually triggered.
Aside from this, there is usually low variation of ~ 10 minutes on the process but it can go up to more than 30 minutes.


## Conclusions

One big difference between CRAN and Bioconductor or rOpenSci is that even if your package is already included each time you want to fix something it gets reviewed by someone. 
This ensures a high quality of the packages, as well as increases the pressure on the package reviewers.
This in turn raises the bar for resubmissions. 

### Reproducibility

<details>
```{r reproducibility, echo = FALSE}
## Reproducibility info
options(width = 120)
sessioninfo::session_info()
```
</details>
