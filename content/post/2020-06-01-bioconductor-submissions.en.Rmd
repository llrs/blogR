---
title: Bioconductor submissions
author: Llu√≠s Revilla Sancho
date: '2020-06-01'
slug: bioconductor-submissions
categories:
  - r
  - Bioconductor
tags:
  - r
  - Bioconductor
authors: []
description: ''
editor_options:
  chunk_output_type: console
featured: no
output:
  code_folding: hide
image:
  caption: ''
  focal_point: ''
subtitle: ''
summary: 'Exploring the submission process to Bioconductor. What happens, how long does it take, what are the common problems and solutions...'
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, warning = FALSE, message = FALSE, error = FALSE,
                      cache = FALSE, echo=FALSE)
```

The other day I was curious about how many submissions are on Bioconductor and how do they work, is there any pattern toward the release cycle or not?

```{r gh}
library("gh")
PR <- gh("GET /search/issues?q=repo:Bioconductor/Contributions+is:issue") # Copied from https://developer.github.com/v3/pulls/
```

There are `r PR$total_count` issues, so we'll need to look for `r round(PR$total_count/100)` queries.

```{r get_issues}
page <- function(query, x){paste0(query, "&page=", x)}
get_issues <- function() {
  query <- "GET /repos/Bioconductor/Contributions/issues?state=all&per_page=100"
  qp <- page(query, 1:15)
  v <- vector("list", length = 17)
  for (i in seq_along(qp)) {
    v[[i]] <- gh(qp[i])
  }
  unlist(v, use.names = FALSE, recursive = FALSE)
}

issues <- get_issues()
```

Once we got all the issues, it's time to tidy and extract the interesting information, 
check when do they happen, by who, when are they closed... 

```{r clean}
clean_issue <- function(x) {
  # Omit pull request I want Package submissions
  if ("pull_request" %in% names(x)) {
    return(NA)
  }
  repos <- str_extract_all(x$body, "https?://github.com/.+/.+")
  repos <- repos[[1]]
  repos <- str_remove(repos, "https?://github.com/")
  pkg_repo <- unlist(str_extract_all(repos, "^[:alnum:]+"), FALSE, FALSE)
  p <- str_remove(unlist(str_extract_all(repos, "/.*$"), FALSE, FALSE), "^/")
  p <- gsub("\\.$", "", p)
  
  list(id = as.numeric(x$number), user = x$user$login, title = x$title, 
       n_comments = x$comments, 
       created = x$created_at, closed = x$closed_at, 
       repos = repos,
       pkg_repo = pkg_repo, 
       package = p,
       assignee = vapply(x$assignees, getElement, name = "login", character(1L)),
       labels = vapply(x$labels, getElement, name = "name", character(1L)))
 }
```


```{r tidy_issues}
library("tidyverse")
library("lubridate")
l <- lapply(issues, clean_issue)
l <- l[lengths(l) == 11] # Expect to delete at least 4 issues
m <- t(simplify2array(l))
m <- as.data.frame(m)
m$created <- unlist(m$created, recursive = FALSE, use.names = FALSE)
# If it is not closed leave it empty
replace <- lengths(m$closed) != 0
unlisted_closed <- unlist(m$closed, recursive = FALSE, use.names = FALSE)
m$closed <- NA
m$closed[replace] <- unlisted_closed

df <- m %>% 
  mutate(id = as.numeric(id),
         title = str_squish(as.character(title)),
         user = as.character(user),
         n_comments = as.numeric(n_comments),
         created = as.Date(created),
         closed = as.Date(closed),
         approved = vapply(labels, function(x){"3a. accepted" %in% x}, logical(1L)),
         n_reviewers = lengths(assignee),
         n_packages = lengths(repos),
         n_labels = lengths(labels),
         package = ifelse(package == "NA", NA, package),
         pkg_repo = ifelse(pkg_repo == "NULL", NA, pkg_repo),
         Approved = case_when(approved ~ "Yes",
                              !approved & !is.na(closed) ~ "No",
                              TRUE ~ "Ongoing"),
         time_opened = if_else(is.na(closed), as.Date(today()), closed)-created,
  ) %>% 
  arrange(id) %>% 
  mutate(i = 1:n())
n_dup <- count(df, package, sort = TRUE) %>% 
  filter(package != "", n != 1) %>% nrow()
```

We can further include those approved because they are on bioconductor but do not have the [approved label](https://github.com/Bioconductor/Contributions/labels/3a.%20accepted) (Sometimes they get accepted but they forget to change labels on the issue). 
We need to be cautious also because there are `r n_dup` packages that have been submitted several times.

```{r check_available}
library("BiocManager")
Bioconductor <- BiocManager::repositories()
bp <- available.packages(contriburl = contrib.url(Bioconductor)[1:4])
lasted <- df %>% 
  group_by(package) %>% 
  filter(!any(approved)) %>% 
  filter(closed == max(closed)) %>% 
  ungroup() %>% 
  select(package, approved)
currently_on_bioc <- lasted$package  %in% rownames(bp)
check <- (currently_on_bioc != lasted$approved) & (currently_on_bioc == TRUE)
approved_packages_wo_label <- df %>% 
  filter(package  %in% lasted$package[check]) %>% 
  group_by(package) %>% 
  filter(!any(approved)) %>% 
  arrange(package, -n_comments) %>% 
  count(sort = TRUE) %>% 
  filter(n == 1) %>% 
  pull(package)
df$approved[df$package %in% approved_packages_wo_label] <- TRUE
```


I omitted packages that appear several times as some of them are due to being on the old tracker.
Using also the CRAN repository we could find which packages where submitted to Bioconductor but end up on CRAN. But as I expect a low number of these I won't check them.

## Exploring the data


```{r warning=FALSE}
# If not closed add the closing time of today
releases <- data.frame(release = paste0("3.", 3:12),
           date = as.Date(c("2016/04/04", "2016/10/18", "2017/04/25", 
                            "2017/10/31", "2018/05/01", "2018/10/31", 
                            "2019/05/03", "2019/10/30", "2020/04/28",
                            "2020/10/01"), format = "%Y/%m/%d"),
           stringsAsFactors = FALSE)

scale_data <- scale_x_date(expand = expansion(add = 10), 
               limits = as.Date(c("2016-06-01", "2020-06-10"), "%Y-%m-%d"))
theme_set(theme_minimal())
df %>% 
  filter(time_opened != 0) %>% 
  ggplot() +
  geom_linerange(aes(y = id, xmin = created, xmax = closed), col = "grey") + 
  geom_point(aes(y = id, created), col = "brown", size = 1) + 
  geom_point(aes(y = id, closed, col = approved, shape = approved), size = 1) + 
  geom_vline(xintercept = releases$date, col = "darkgreen") + # Releases dates
  geom_text(data = releases, aes(x = date, y = c(rep(1200, 5), rep(300, 5)),
           label = release)) + # Release dates

  labs(title = "Issues that are open at least a day", 
       subtitle = "Green lines indicate Bioconductor releases.",
       x = element_blank(), y = element_blank(), 
       col = "Approved", shape = "Approved",
       caption = "Author: @Lluis_Rev") +
  scale_data +
  scale_y_continuous(expand = expansion(add = 10))
```

On this plot we can see almost everything, date of creation, time opened, when was closed, in which release is included if accepted and the rate of submissions to Bioconductor. 
What we miss is about the authors submitting the packages and about the packages themselfs. 

## Submitting authors

One of the core strength of R is the open community. There have been `r length(unique(df$user))` different users submitting a package.

```{r users_submitting}
usr_diff_pkg <- df %>% 
  filter(!is.na(closed)) %>% 
  group_by(user) %>% 
  distinct(package) %>% 
  count(sort = TRUE)

usr_diff_pkg %>% 
  ungroup() %>% 
  count(n) %>% 
  ggplot() +
  geom_col(aes(n, nn)) +
  labs(y = "Contributors", x = "Packages", 
       title = "Number of packages submitted by a contributor") +
  scale_y_continuous(expand = expansion(add = c(0, 10))) +
  scale_x_continuous(breaks = rev(unique(usr_diff_pkg$n)), 
                     expand = expansion(add = 0.05))
```

We can clearly see that most of the submissions are the first submission of the author, and quickly it falls close to 0.

```{r users_ratio}
usr_ratio <- df %>% 
  filter(!is.na(closed)) %>% 
  group_by(user) %>% 
  summarise(ratio = sum(approved)/n()) %>% 
  arrange(ratio)

usr_ratio %>% 
  ggplot() +
  geom_bar(aes(ratio)) +
  labs(title = "User success submitting packages",
       x = "Success ratio", y = "Users")
```

Most of the users get their submission included at Bioconductor at the first try. Few need two submissions and some do not get their package included on Bioconductor.

```{r users}
usr_success <- usr_diff_pkg %>% 
  inner_join(usr_ratio)

ggplot(usr_success) +
  geom_count(aes(n, ratio)) +
  labs(x = "Packages", y = "Approval success ratio", size = "Users",
       title = "Submitting more packages increaes approval rate") +
  scale_x_continuous(expand = expansion(add = 0.25), breaks = 1:14) +
  theme(panel.grid.minor.x = element_blank())
```

If users submit more packages they usually get them approved.

```{r submissions}
df %>% 
  mutate(year = year(created)) %>% 
  group_by(year) %>% 
  summarise(n = n(), ratio = sum(approved)/n) %>% 
  ungroup() %>% 
  ggplot() +
  geom_col(aes(year, n, fill = ratio)) + 
  labs(title = "Yearly submissions and approval", 
       y = "Issues", x = element_blank(), 
       fill = "Approval ratio") +
  scale_fill_continuous(low = "white", high = "darkgreen", limits = c(0, 1))
```

Around 50% of the ~400 packages submitted are approved. 

So if you have a package that fits Bioconductor you'll get fairly well on the submission process. But I always recommend the lengthy pages for developers about the [submission process](https://bioconductor.org/developers/package-submission/) and the [packages guidelinines and requirements](https://bioconductor.org/developers/package-guidelines/). As my experience most of the reasons for not accepting a packages is not following the guidelines. 

# Reviewers

If your package fits Bioconductor you will get assigned a reviewer.
Many submissions (~33%) do not get a reviewer assigned and the package is not included on Bioconductor's repository, most (~90%) of the cases this happens the same day of the submission. 
But once they get one reviewer ~82% of them are approved.

```{r reviewers, include=FALSE}
df %>% 
  group_by(n_reviewers) %>% 
  count(Approved) %>% 
  ungroup() %>% 
  mutate(ratio = n/sum(n)) %>% 
  arrange(-ratio, n)

df %>% 
  filter(n_reviewers == 0) %>% 
  group_by(time_opened) %>% 
  count(Approved) %>% 
  ungroup() %>% 
  mutate(ratio = n/sum(n)) %>% 
  arrange(-ratio)

df %>% 
  group_by(n_reviewers) %>% 
  count(Approved) %>% 
  ungroup() %>% 
  filter(n_reviewers != 0) %>% 
  mutate(ratio = n/sum(n)) %>% 
  group_by(Approved) %>% 
  summarise(fr = sum(ratio))
```

There are 9 usual reviewers:

```{r reviewers_frequency}
normal_reviews <- df %>% 
  filter(n_reviewers == 1, n_labels >= 1, n_comments > 1,
         !is.na(closed)) %>% 
  mutate(Reviewer = unlist(assignee))

top_reviewers <- normal_reviews %>% 
  count(Reviewer, sort = TRUE) %>% 
  top_n(9, wt = n) %>% 
  pull(Reviewer)

normal_reviews %>% 
  mutate(year = year(created)) %>% 
  group_by(year) %>% 
  count(Reviewer) %>% 
  mutate(share = n/sum(n),
         Reviewer = fct_reorder2(Reviewer, year, n)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_line(aes(year, share, col = Reviewer)) +
  scale_y_continuous(labels = scales::percent) +
  labs(x = element_blank(), y = element_blank(),
       title = "Share of issues reviewed")
```

Probably you might get assigned the project leader Martin Morgan, but you can work with any other reviewer: `r paste(top_reviewers, collapse = ", ")`.

```{r reviewer_comments}
normal_reviews %>% 
  group_by(Reviewer) %>% 
  count(Approved) %>% 
  mutate(ratio = n/sum(n), total = sum(n),
         Reviewer = fct_reorder(Reviewer, ratio)) %>% 
  ungroup() %>% 
  filter(Approved == "Yes", total  > 50) %>% 
  ggplot() +
  geom_point(aes(total, ratio, col = Reviewer)) + 
  scale_y_continuous(labels = scales::percent, limits = c(0, 1), 
                     expand = expansion(mult = 0, add = 0)) +
  labs(x = "Issues handled", y = "Approval ratio",
       title = "Reviewers approval Ratio")
```

The reviews are fairly done by all the members. We can see that all of them approves more than 70% of the packages assigned. 

Most of the reviewers take few days until the issue is closed.

```{r reviewers_time}
breaks <- function(limits) {
  seq(from = 0, to = floor(limits[2]), by = 100)
}

normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  ggplot() +
  ggbeeswarm::geom_quasirandom(aes(Reviewer, time_opened, 
                                   col = Approved, shape = Approved), 
                               size = 0.75) +

  labs(y = "Days open", title = "Time open by reviewers")

# Focusing a bit

normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  ggplot() +
  ggbeeswarm::geom_quasirandom(aes(Reviewer, time_opened, 
                                   col = Approved, shape = Approved)) +
  coord_cartesian(ylim = c(0, 150)) +
  scale_y_continuous(expand = expansion(mult = 0, add = 0)) +
  labs(y = "Days open", title = "Time open by reviewers", 
       subtitle = "A zoom")
```

Usually more time reviewing do not mean closing the issue without being accepted. 

```{r reviewer_time_diff}
reviewer_time <- normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Reviewer) %>% 
  summarise(m = median(time_opened), me = mean(time_opened), n = n()) %>% 
  ungroup() %>% 
  arrange(m)
           
global_medians_time <- normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Approved) %>% 
  summarise(m = median(time_opened), me = mean(time_opened), n = n())
  
normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Reviewer, Approved) %>% 
  summarise(m = median(time_opened), me = mean(time_opened), n = n()) %>% 
  ungroup() %>% 
  mutate(Reviewer = fct_relevel(Reviewer, reviewer_time$Reviewer)) %>% 
  ggplot() +
  geom_hline(data = global_medians_time, 
             aes(yintercept = m, col = Approved), linetype = "dotted") +
  geom_point(data = reviewer_time, aes(fct_relevel(Reviewer, Reviewer), 
                                       m, size = n)) +
  geom_point(aes(Reviewer, m, col = Approved, shape = Approved, size = n)) +
  labs(x = element_blank(), y = "Days (median)", 
       title = "Reviewers speed to close", 
       subtitle = "In black all reviews together",
       size = "Reviews") +
  scale_y_continuous(limits = c(0, 90), expand = expansion(add = c(1, 0)), 
                     breaks = seq(from = 0, to = 90, by = 20)) +
  scale_shape_manual(values = c(15, 17)) +
  scale_x_discrete(expand = expansion(add = 0.1)) +
  theme_minimal()
```

Correction! Some reviewers close later submissions that are not approved. They might wait longer to close the issues without approving them, or maybe they prefer to suggest modifications and a second submission of the same package. 
Others close way faster than they accept the packages. In general you can expect more than 40 days review.

They might accept faster packages but it is because they provide faster feedback with more comments?

```{r reviewers_comments}
normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  ggplot() +
  ggbeeswarm::geom_quasirandom(aes(Reviewer, n_comments, 
                                   col = Approved, shape = Approved), 
                               size = 0.75) +

  labs(y = "Comments", title = "Comments on the issue", x = element_blank())
```

Many of the comments I suspect are automatic messages from the bot about building and receiving commits. But apparently there isn't a difference between them.

```{r reviewer_comment_diff}
reviewer_comments <- normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Reviewer) %>% 
  summarise(m = median(n_comments), me = mean(n_comments), n = n()) %>% 
  ungroup() %>% 
  arrange(m)

global_medians_comments <- normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Approved) %>% 
  summarise(m = median(n_comments), me = mean(n_comments), n = n())

normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  group_by(Reviewer, Approved) %>% 
  summarise(m = median(n_comments), me = mean(n_comments), n = n()) %>% 
  ungroup() %>% 
  mutate(Reviewer = fct_relevel(Reviewer, reviewer_comments$Reviewer)) %>% 
  ggplot() +
  geom_hline(data = global_medians_comments, 
             aes(yintercept = m, col = Approved), linetype = "dotted") +
  geom_point(data = reviewer_comments, aes(fct_relevel(Reviewer, Reviewer), 
                                       m, size = n)) +
  geom_point(aes(Reviewer, m, col = Approved, fill = Approved, shape = Approved, size = n)) +
  labs(x = element_blank(), y = "Comments (median)", 
       title = "Comments on the issues", subtitle = "In black all reviews together",
         size = "Reviews") +
  scale_y_continuous(limits = c(0, 60), expand = expansion(add = c(1, 0)), 
                     breaks = seq(from = 0, to = 70, by = 20)) +
  scale_shape_manual(values = c(15, 17)) + 
  theme_minimal() +
  scale_x_discrete(expand = expansion(add = 0.1))
```

Here almost all the reviewers have more comments on approved packages. Even if this is due to automatic messages it seems like responding and giving feedback to the reviewers as the authors address the points provided by the reviewer increases acceptance. Usually more than 20 comments on the issue will be enough but the more feedback, the better.

```{r acceptance_comments, include = FALSE}
normal_reviews %>%  
  group_by(Approved) %>% 
  summarise(median = median(n_comments), mean = mean(n_comments))
```

Taking both information together we can see the pattern for all the reviewers:

```{r reviewers_comments_time}
normal_reviews %>% 
  filter(Reviewer  %in% top_reviewers) %>% 
  ggplot() +
  geom_point(aes(time_opened, n_comments, col = Approved, shape = Approved), 
             size = 0.75) +
  scale_x_continuous(breaks = breaks) +
  scale_y_continuous(breaks = breaks) +
  facet_wrap(~Reviewer, scales = "free") +
  labs(x = "Days opened", y = "Comments", 
       main = "Comments", title = "Comments and open days per reviewer")
```

Most of the not approved issues have less comments and usually remain less days open.

## Rushing?

Most of the issues are handled quite fast, and it seems like there isn't a rush to publish:

```{r submission_rate}
df %>% 
  mutate(md  = as.numeric(format(created, "%j")),
         year = year(created)) %>% 
  group_by(md) %>% 
  summarise(n = median(n())) %>% 
  ungroup() %>% 
  ggplot() + 
  geom_point(aes(md, n)) + 
  labs(title = "Median daily submissions", 
       x = "Day of year", y = "Issues opened") +
  scale_x_continuous(expand = expansion(add = 5))
```

So most days there is a new package submission and on the best day there are 8. 
There doesn't seem to be a seasonality neither. 


Using the dates of new [Bioconductor release](https://bioconductor.org/about/release-announcements/) we can check if there is some rush to submit packages closer to the new release:

```{r margin_submission}
release_attempt <- function(x, release = releases) {
  diff_time <- x - release$date
  pre_release <- diff_time < 0
  pick <- which(diff_time[pre_release] == max(diff_time[pre_release]))
  data.frame("release" = release$release[pre_release][pick], 
    "margin" = abs(diff_time[pre_release][pick]), stringsAsFactors = FALSE)
}

ra <- lapply(df$created, release_attempt)
r <- lapply(ra, function(x){x$release})
r[lengths(r) == 0] <- NA
r <- unlist(r, FALSE, FALSE)
m <- lapply(ra, function(x){x$margin})
m[lengths(m) == 0] <- NA
m <- unlist(m, FALSE, FALSE)
m <- as.difftime(m, units = "days")
df2 <- df %>% 
  mutate(release = r, margin = m,
         devel = release == "3.11" & approved & margin < 30)
df2 %>% 
  ggplot() +
  geom_histogram(aes(margin), bins = 40) +
  geom_vline(xintercept = 30) +
  scale_y_continuous(expand = expansion(add = c(0, 5))) +
  scale_x_continuous(expand = expansion())  + 
  labs(title = "Days till next release", y = "Issues", x = "Days")
```

The vertical line indicates the usual time the submissions are no longer accepted (around 30 days before the release day). 
So it seems like people submit close to the date but much consistently around the period as previously seen. 

```{r margin_submission_accepted, include=FALSE}
df2 %>% 
  filter(margin < 30) %>% 
  count(Approved) %>% 
  knitr::kable(col.names = c("Approved", "Issues"), 
               caption = "Packages submitted 30 days before a release", 
               align = "c")
df2 %>% 
  filter(margin > 30) %>% 
  count(Approved) %>% 
  knitr::kable(col.names = c("Approved", "Issues"),
               caption = "Packages submitted more than 30 days before a release", 
               align = "c")
```

Those that submit closer to the date of release have higher rates of not being included on Bioconductor.

```{r worst_scenario}
latest_submission <- max(df2$margin, na.rm = TRUE)

df2 %>% 
  filter(!(time_opened == 0 & !approved)) %>% 
  ggplot() +
  geom_vline(xintercept = 30) +
  geom_hline(yintercept = latest_submission*c(1:4), col = "darkgrey") +
  geom_point(aes(margin, time_opened, col = Approved, shape = Approved)) +
  geom_point(data = ~filter(.x, devel), aes(margin, time_opened), col = "grey") +
  ggplot2::annotate(geom = "rect", xmin = 0, ymin = latest_submission,
            xmax = max(df2$margin, na.rm = TRUE), ymax = max(df2$time_opened) + 10, 
            fill = "orange", alpha = 0.25) +
  ggplot2::annotate(geom = "rect", xmin = 0, ymin = 0,
            xmax = 30, ymax = max(df2$time_opened) + 10, 
            fill = "red", alpha = 0.25) +
  ggplot2::annotate(geom = "text", x = 100, y = 540, 
                    label = "Missed release") +
  ggplot2::annotate(geom = "text", x = 13, y = 700, 
                    label = "Submitted right before a release", 
                    angle = 90, hjust = 1, vjust = 1) +
  scale_x_continuous(expand = expansion(add = 1)) +
  scale_y_continuous(expand = expansion(add = 9)) +
  scale_color_discrete(na.value = "grey") +
  labs(x = "Days till release", y = "Days open",
       title = "Packages not closed the same day as submitted",
       subtitle = "In red the worse time to submit. Each horitzonal bar indicates a missed release")
```

Very few packages went to the worst scenario: submitted right before a deadline and then it wasn't accepted until many releases later. However there is a curious effect the closer the submission is to the release day the accepted packages have shorter (in time) reviews

```{r open_releases}
df2 %>% 
  ggplot() +
  geom_point(aes(created, time_opened, col = Approved, shape = Approved)) +
  geom_vline(data = releases, aes(xintercept = date), alpha = 0.5, 
             col = "darkgreen") + # Release dates
  geom_text(data = releases, aes(x = date, y = rep(600, 10),
           label = release), col = "darkgreen") + # Release dates
  scale_y_continuous(expand = expansion(add = 6)) +
  scale_color_viridis_d() +
  scale_data +
  labs(x = element_blank(), y = "Days open", 
       title = "Time open") 
```

There doesn't seem to be a rush toward the release date, although several packages open the issue when there is less than 30 days for the release (the usual time that the submission queue is on hold)
  

I expected to see longer review time for the issues submitted closer to the release but we don't see it. However we see that less time is spend on the submissions right after the previous release. 

## Pitfalls

We have seen mostly the path to success, but in order to improve the process we must look what lead to having the packages not approved.

We can check if packages

```{r pkg_source}
df2 %>% 
  filter(Approved != "Ongoing",
         n_packages == 1) %>% 
  group_by(same_submitter = ifelse(pkg_repo != user, "No", "Yes")) %>% 
  count(Approved) %>% 
  mutate(ratio = n/sum(n), total = sum(n), pos = paste0(n, collapse = "/")) %>% 
  ggplot() +
  geom_col(aes(fct_relevel(same_submitter, c("Yes", "No")), n, fill = Approved)) +
  geom_text(aes(fct_relevel(same_submitter, c("Yes", "No")), total*1.05, label = pos)) +
  labs(x = "Repository belongs to submitter", y = "Submissions",
       title = "Success if repository belongs to the submitter")
```

When the user that submits the package is the owner of the repository then it is more likely that the package is accepted.

```{r time_rejected}
df2 %>% 
  filter(Approved == "No") %>% 
  ggplot() + 
  geom_histogram(aes(time_opened), bins = 50) +
  labs(x = "Days open", y = "Issues", 
       title = "Most not approved packages get closed the same day") 
```

Most packages are closed fast but some review are longer than a year! Those closed fast are automatically done by the bot due to several reasons.

```{r repo_links}
rejected <- df2 %>% 
  filter(Approved == "No")
rejected %>% 
  count(n_packages) %>% 
  filter(n_packages != 1) %>% 
  knitr::kable(col.names = c("Number of packages", "Times"), 
               caption = "Issues with more than one package",
               align = "c")
rejected %>%
  filter(n_packages == 1) %>% 
  count(package, sort = TRUE) %>% 
  head() %>% 
  knitr::kable(col.names = c("Name", "Packages"), 
               caption = "Issues with more than one package",
               align = "c")
```

It is equally probable to not provide a link or to provide two. However many times the template is used as is and the link to the name of the repository remains "yourpackagename". 

```{r comments}
rejected %>% 
  count(n_comments, sort = TRUE) %>% 
  head() %>% 
  knitr::kable(col.names = c("Comments", "Issues"), 
               align = "c")
```

Most of the rejected submissions is done automatically by the "[bioc-issue-bot](https://github.com/bioc-issue-bot)", with a brief message.


```{r ending}
rejected %>% 
  filter(n_packages == 1) %>% 
  mutate(ending = str_extract(package, "\\..+$")) %>% 
  select(id, repos, package, ending) %>% 
  filter(!is.na(ending)) %>% 
  count(ending, sort = TRUE) %>% 
  head() %>% 
  knitr::kable(col.names = c("Ending", "Number of issues"), 
               caption = "Ending of rejected issues",
               align = "c")
```

There are some other time when the user provides a link to a compressed file, or it ends incorrectly formatted.


```{r labels}
rejected %>% 
  count(n_labels) %>% 
  knitr::kable(col.names = c("Number of labels", "Number of issues"),
               caption = "Labels of rejected packages",
               align = "c")
```

Usually this means they do not get assigned a reviewer or built on the Bioconductor server.

```{r upset}
ups <- rejected %>% 
  filter(n_labels > 1) %>% 
  select(i, id, labels) %>% 
  unnest(labels) %>% 
  pivot_wider(names_from = labels, values_from = id) %>% 
  mutate(across(where(is.numeric), function(x){!is.na(x)})) %>%
  mutate(across(where(is.logical), as.integer))
ups <- ups[, -1]
ups <- as.data.frame(ups)
colnames(ups) <- make.names(colnames(ups))
library("UpSetR")
upset(ups, sets = colnames(ups), order.by = "freq", decreasing = TRUE, 
      nintersects = 10)
```

Looking at which labels go together, if the review starts the next halting point is an error on the build process.

## Conclusion

Most of the packages submitted to Bioconductor are accepted. 
Those that are not accepted are usually due to submission formatting issues and catch up automatically by the bioc-issue-bot. 
Reviewers provide a lot of feedback that if followed leads to acceptance of the package.
Some packages are submitted right before a release and miss it, while others undergo a long review and miss several releases. 

### Reproducibility

<details>
```{r reproducibility, echo = FALSE}
## Reproducibility info
options(width = 120)
sessioninfo::session_info()
```
</details>
