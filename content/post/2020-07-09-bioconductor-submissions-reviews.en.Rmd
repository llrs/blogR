---
title: 'Bioconductor submissions: reviews'
author: Llu√≠s Revilla Sancho
date: '2020-07-31'
slug: bioconductor-submissions-reviews
categories:
  - Bioconductor
  - r
tags:
  - Bioconductor
  - r
  - reviews
authors: []
description: 'Looking in detail to Bioconductor sumbissions: interactions between bots, reviewers and the community.'
editor_options:
  chunk_output_type: console
featured: yes
draft: false
image:
  caption: ''
  focal_point: ''
subtitle: 'The second part of Bioconductor submissions'
summary: 'Looking in detail to Bioconductor sumbissions: interactions between bots, reviewers and the community.'
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(collapse = TRUE, warning = FALSE, message = FALSE, 
                      echo = FALSE, cache = TRUE)
```

First post  is on [Bioconductor submissions](https://llrs.dev/2020/06/bioconductor-submissions/) raised some questions comments but at the time I didn't have a good way to answer them:

- issues get closed after they got assigned a reviewer and before the reviewer actually gets a chance to start the review.
- issues assigned to multiple people or issues that switched reviewers

To answer both of them I needed more information.
On the previous post I only gathered the information of the state of the issues at that moment. 
This excluded label changes, reviewer changes, renaming the issues, who commented on the issues and many more things.
To retrieve these information from github I developed a [new package](https://llrs.dev/2020/06/social-github/) [`{socialGH}`](https://github.com/llrs/socialGH) which downloads it from [Github](https://github.com) to make the analysis possible.

```{r reading, eval=FALSE}
library("socialGH")
repo <- "Bioconductor/Contributions"
gi <- get_issues(repo)
i <- unique(gi$id)
# gt <- get_timelines(repo) there's a limit of 40000 so we cannot use it.
gt <- lapply(i, get_timelines, repository = repo)
gt2 <- do.call(rbind, gt)
library("tidyverse")
theme_set(theme_minimal())
gi2 <- gi %>% 
  select(-n_comments) %>% 
  mutate(actor = poster, event = "created")
column <- intersect(colnames(gt2), colnames(gi2))
g <- rbind(gi2[, colnames(gt2)], gt2) %>% 
  arrange(id, created) %>% 
  group_by(id) %>% 
  mutate(event_n = 1:n(),
         event = unlist(event, FALSE, FALSE),
         state = ifelse(event_n == 1, list("opened"), state))
pr <- g %>% 
  ungroup() %>% 
  filter(event %in% c("merged", "committed")) %>% 
  pull(id)
g2 <- g %>% 
  filter(!id %in% pr) %>% 
  mutate(approved = any(label == "3a. accepted"),
         Approved = case_when(any(approved) ~ "Yes",
                              sum(event == "closed") >= sum(event == "reopened") ~ "No",
                              TRUE ~ "Ongoing"))
saveRDS(g2, file = "static/20200818_github_data.RDS")
```

Now that we have more data about the issues we can plot them similarly to what we did on the previous post:

```{r first_plot}
library("socialGH")
library("tidyverse")
theme_set(theme_minimal())
# If not closed add the closing time of today
g2 <- readRDS(here::here("static", "20200818_github_data.RDS")) %>% 
  mutate(
    approved = any(str_detect(unlist(label[event %in% c("labeled", "unlabeled")]), "accept")),
    Approved = case_when(any(approved) ~ "Yes",
                              sum(event == "closed") >= sum(event == "reopened") ~ "No",
                              TRUE ~ "Ongoing"))
link_issue <- function(x) {
  socialGH::link_issue("Bioconductor/Contributions", x)
}
releases <- data.frame(release = paste0("3.", 3:12),
           date = as.POSIXct(c("2016/04/04", "2016/10/18", "2017/04/25", 
                            "2017/10/31", "2018/05/01", "2018/10/31", 
                            "2019/05/03", "2019/10/30", "2020/04/28",
                            "2020/10/01"), format = "%Y/%m/%d"),
           stringsAsFactors = FALSE)

scale_data <- scale_x_datetime(expand = expansion(add = 10), 
               limits = as.POSIXct(c("2016-06-01", "2020-06-10"), "%Y-%m-%d"))

cut <- 5
g2 %>% 
  ggplot() +
  geom_point(aes(created, id, 
                 col = fct_lump_n(event, cut),
                 shape = fct_lump_n(event, cut))) + 
  geom_vline(xintercept = releases$date, col = "#1a81c2") + # Releases dates
  geom_text(data = releases, aes(x = date, y = c(rep(1200, 5), rep(300, 5)),
           label = release)) + # Release dates
  scale_data +
  labs(x = "Events", y = "Issue", col = "Type", shape = "Type",
       title = "Events on issues") +
  scale_color_viridis_d() +
  theme(legend.position = "bottom", legend.direction = "horizontal") + 
  guides(colour = guide_legend(nrow = 1), shape = guide_legend(nrow = 1))
```

We can see that sometimes the issues remained silent for several months and then had a high level of events, or a single one (closing).

Compare to the previous version it is surprising to see that one of the earliest issues still gets new events to date. 
Apparently [issue 51](https://github.com/Bioconductor/Contributions), and others, are being used to test the Bioconductor builder. 

```{r exclude_testing}
g2 <- filter(g2, !id %in% c(1:5, 51, 587, 764, 1540, 1541))
```


```{r summarizing}
get_element <- function(x, name) {
  if (!is.null(names(x))) {
    getElement(x, name)
  } else {
    NA_character_
  }
} 
trelative <- function(x) {
  created <- x$created
  event <- x$event
  start <- created[event == "created"]
  k <- event == "closed"
  if (any(k)){
    closing <- created[which.max(k)]
  } else {
    closing <- max(created)
  }
  
  o <- difftime(created[!is.na(created)], start, units = "days")
  as.numeric(o)
}
g2 <- g2 %>% 
  mutate(reviewer = vapply(assignee, get_element, name = "user", character(1)),
         actor = vapply(actor, get_element, name = "user", character(1L)))
full <- g2 %>%  
  nest_by() %>% 
  summarize(time_relative = trelative(data), created = data$created) %>% 
  inner_join(g2) %>% 
  unique()
```


```{r by_issue}
reviewers <- function(assigners, unassigners) {
  ta <- table(assigners)
  tu <- table(unassigners)
  y <- 0
  n <- sum(ta) - sum(tu)
  reviewers <- vector("character", n)
  for(reviwer in names(ta)) {
    x <- ta[reviwer]-tu[reviwer]
    if (x >= 1 | is.na(x)){
      y <- y + 1
      reviewers[y] <- reviwer
    }
  }
  reviewers
}

by_issue <- g2 %>% 
  group_by(id) %>% 
  summarize(time_window = difftime(max(created), min(created), units = "days"),
            events = n(), 
            diff_users = n_distinct(actor),
            diff_events = n_distinct(event),
            Approved = unique(Approved),
            approved = unique(approved),
            assignments = sum(event %in% "assigned"),
            reassigned = any(event %in% "unassigned"),
            assigners = list(reviewer[event %in% "assigned"]),
            unassigners = list(reviewer[event %in% "unassigned"]),
            reviewers = list(reviewers(unlist(assigners, FALSE, FALSE), 
                                    unlist(unassigners, FALSE, FALSE))),
            reviewer_comments = sum(event == "commented" & 
                                      actor %in% unlist(reviewers), na.rm = TRUE),
            closers = list(actor[event == "closed"]),
            openers = list(actor[event == "reopened"]),
            closed = sum(event == "closed") >= sum(event == "reopened") & any(event == "closed"),
            closer = list(setdiff(unlist(closers, FALSE, FALSE), 
                                    unlist(openers, FALSE, FALSE))),
            labels_added = list(label[event == "labeled"]),
            labels_removed = list(label[event == "unlabeled"]),
            labels_final = list(setdiff(unlist(labels_added, FALSE, FALSE), 
                                    unlist(labels_removed, FALSE, FALSE))),
            check_labels = all(unlist(labels_final, FALSE, FALSE) %in%
                                 label[event == "created"]),
            submitter = actor[event == "created"]
            
) %>% 
  mutate(n_reviewers = lengths(reviewers),
         n_closers = lengths(closer))

by_issue1 <- g2 %>% 
  count(event) %>% 
  filter(event != "created") %>% 
  pivot_wider(values_from = n, names_from = event, values_fill = 0) %>% 
  nest_by(.key = "event")
by_issue2 <- g2 %>% 
  count(actor) %>% 
  pivot_wider(values_from = n, names_from = actor, values_fill = 0) %>% 
  nest_by(.key = "actor")

by_issue <- by_issue %>% 
  inner_join(by_issue1) %>% 
  inner_join(by_issue2)
```


```{r by_user}
by_user <- g2 %>%
  group_by(actor) %>% 
  summarize(
    actions = n(),
    issues_participated = n_distinct(id),
    issues = list(unique(id)),
    events_participated = n_distinct(event),
  ) %>% 
  mutate(is_reviewer = actor %in% unlist(by_issue$reviewers, FALSE, FALSE))

by_user1 <- g2 %>% 
  group_by(actor) %>% 
  count(event) %>% 
  pivot_wider(values_from = n, names_from = event, values_fill = 0) %>% 
  nest_by(.key = "event")
by_user2 <- g2 %>% 
  group_by(actor) %>% 
  count(id) %>% 
  pivot_wider(values_from = n, names_from = id, values_fill = 0) %>% 
  nest_by(.key = "ids")

by_user <- by_user %>% 
  inner_join(by_user1) %>% 
  inner_join(by_user2)
library("ggrepel")
by_user %>% 
  filter(is_reviewer) %>%
  ggplot() + 
  geom_point(aes(actions, issues_participated)) +
  geom_text_repel(aes(actions, issues_participated, label = actor)) +
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(trans = "log10") +
  labs(size = "Users", col = "Different events", x = "Events", y = "Issues",
       title = "Reviewers involvement")
by_user %>% 
  filter(!is_reviewer & actor != "bioc-issue-bot" & !is.na(actor)) %>%
  ggplot() + 
  geom_count(aes(actions, issues_participated)) +
  scale_color_viridis_d() + 
  scale_x_continuous(trans = "log10") +
  scale_y_continuous(trans = "log10") +
  scale_radius(breaks = c(1, 10, 20, 30, 40)) +
  geom_text_repel(aes(actions, issues_participated, label = actor), 
                data = . %>% filter(issues_participated > 10 | actions > 100)) +
  labs(size = "Users", col = "Different events", x = "Events", y = "Issues",
       title = "Users involvement")
```


```{r by_event}
by_event1 <- g2 %>% 
  group_by(event) %>% 
  count(actor) %>% 
  pivot_wider(names_from = actor, values_from = n, values_fill = 0) %>% 
  nest_by(.key = "actor")
by_event2 <- g2 %>% 
  group_by(event) %>% 
  count(id) %>% 
  pivot_wider(names_from = id, values_from = n, values_fill = 0) %>% 
  nest_by(.key = "id") 

by_event <- g2 %>% 
  group_by(event) %>% 
  summarize(
    n = n(),
    ids = list(unique(id)),
    actors = list(unique(actor)),
    diff_id = n_distinct(id),
    diff_actor = n_distinct(actor))
by_event <- by_event %>% 
  inner_join(by_event1, by = "event") %>% 
  inner_join(by_event2, by = "event")
```

```{r by_event_actor_id}
by_actor_event_id <- g2 %>% 
  group_by(event, actor, id) %>% 
  count()
```

# Events

We cab count how many users and issues have been involved with each event type:

```{r events_view}
by_event %>% 
  ggplot() + 
  geom_text_repel(aes(diff_id, diff_actor, label = event)) +
  scale_y_continuous(trans = "log10") +
  scale_x_continuous(trans = "log10") +
  labs(title = "Events", x = "Number of different issues", 
       y = "Number of different users")
```

We can see that few issues are locked or comments deleted.
There is an almost equal amount of labeling and unlabeling, performed by few people but on lots of issues.
There is a group of mentioning, commenting and subscribing too.
Many people is involved on commenting and creating submissions. 

Looking a bit further on the issues we can look at the events that take place:

```{r second_plot}
full %>% 
  filter(event != "created") %>% 
  count(event) %>% 
  ungroup() %>% 
  arrange(id, event, n) %>% 
  ggplot() +
  geom_tile(aes(id, fct_reorder(event, n, .fun = sum), col = n)) +
  scale_color_continuous(expand = expansion(), trans = "log10", 
                         high = "#132B43", low = "#56B1F7") +
  labs(y = element_blank(), x = "Issue", title = "Events per issue", 
       col = "Times")
```

We can see that most issues have few events which agrees with the previous findings that issues are handled fairly and expeditiously.

The most common event are comments, mentions and the rarest events are deleting comments, locking or referencing them. 

```{r events_time}
unit <- "days"
g2 %>% 
  group_by(id) %>% 
  filter(event_n == max(event_n)) %>% 
  ungroup() %>% 
  ggplot() +
  geom_histogram(aes(event_n), bins = 40) +
  labs(x = "Events", y = "Issues", title = "Events per issue")
diff_time <- g2 %>% 
  group_by(id) %>% 
  summarise(open_time = difftime(max(created), min(created), units = unit),
            n = max(event_n), 
            id = unique(id),
            slope = n/as.numeric(open_time)) %>% 
  ungroup()
diff_time %>%   
  ggplot() +
  geom_point(aes(open_time, n, col = slope)) +
  scale_color_continuous(expand = expansion(), trans = "log10",
                         high = "#132B43", low = "#56B1F7") +
  labs(y = "Events", x = glue::glue("Time open ({unit})"), 
       col = glue::glue("Events per {unit}"), 
       title = "Number of events and time open") +
  scale_x_continuous(breaks = 1:7*365, labels = function(x) {paste(x/365, "year")}) +
  theme(axis.text.x = element_text())

diff_time %>% 
  filter(open_time <= median(diff_time$open_time)) %>% 
  ggplot() +
  geom_point(aes(open_time, n, col = slope)) +
  scale_color_continuous(expand = expansion(), trans = "log10", 
                         high = "#132B43", low = "#56B1F7") +
  labs(y = "Events", 
       x = glue::glue("Time open ({unit})"), 
       col = glue::glue("Events per {unit}"), 
       title = "Number of events and time open",
       subtitle = "A zoom to the fastest half") +
  scale_x_continuous(breaks = 1:7*7, labels = function(x) {paste(x/7, "weeks")}) +
  theme(axis.text.x = element_text())
```

Some submissions have many events while others have few events but last longer.
This is without looking at issues that were closed and later reopened. 
We can see that in a short amount of days a lot of events can be triggered.
This is mostly that for each version update there are at least two messages on the issue.

```{r assignments}
by_issue %>% 
  ggplot() +
  geom_count(aes(n_reviewers, assignments, col = reassigned, 
                 shape = reassigned)) +
  labs(x = "Final reviewers", y = "Assigned", title = "Reviewers", 
       col = "Reassigned?", shape = "Reassigned?", size = "Submissions") +
  scale_color_brewer(labels = c("No", "Yes"), type = "qual") +
  scale_shape(labels = c("No", "Yes")) +
  scale_size(trans = "log10")
```

We can see that usually some adjustment to reviewers is made usually changing them but some times they are added to have more than 1 reviewer (`r sum(by_issue$assignments > 1)`).
Almost all the submitted packages without a reviewer (`r sum(by_issue$assignments == 0)` submissions) were rejected except for three: `r socialGH::link_issue("Bioconductor/Contributions", 81:83)` that were reviewed by `r socialGH::link_profile("vobencha")` even if not officially assigned.
Some of these were rejected because they didn't pass some automatic check and other after preliminary inspection.

```{r open_close2}
by_issue %>% 
  rowwise(id) %>% 
  mutate(n_openers = n_distinct(openers),
         n_closers = n_distinct(closers)) %>% 
  ggplot() +
  geom_count(aes(n_closers, n_openers)) +
  scale_radius(trans = "log10") +
  facet_wrap(~Approved) +
  labs(x = "Closers", y = "Openers", title = "Issues closers and reopeners", 
       subtitle = "Approved?", size = "Submissions")
```

We can see that is common to close and reopen issues, but they are generally done by the same people (the reviewer or the original submitter)

```{r submission_acceptance}
revi <- by_issue %>% 
  filter(lengths(reviewers) != 0)

reviwer_didnt_close <- revi %>% 
  filter(!is.na(closer),
         closer %in% unlist(reviewers, FALSE, FALSE)) %>% 
  pull(id)

author_closed <- revi %>% 
  filter(!is.na(closer), submitter %in% closer) %>% 
  pull(id)

revi_sum <- revi %>% 
  filter(!id %in% author_closed,
         n_reviewers == 1) %>% 
  mutate(reviewer = unlist(reviewers, FALSE, FALSE),
         reviewer_commented = ifelse(reviewer_comments != 0, "commented", "not commented")) %>% 
  group_by(reviewer, reviewer_commented, Approved) %>% 
  count() %>% 
  group_by(reviewer) %>% 
  mutate(perc = n/sum(n)) %>% 
  arrange(reviewer, reviewer_commented, Approved)

revi %>% 
  ggplot() +
  geom_jitter(aes(Approved, reviewer_comments, 
                  col = Approved, shape = Approved), height = 0) +
  facet_wrap(~n_reviewers, drop = TRUE) +
  labs(x = element_blank(), y = "Reviewers comments", title = "Comments from reviewers",
       subtitle = "Reviewers assigned:")
```

On submissions with a reviewer assigned that were closed by someone (not the submitter), we can see here that reviews with more than one reviewer do not lead to significantly more comments from the reviewers.

Although it seems like this leads to have the package approved. 

```{r reviews}
revi %>% 
  mutate(comments = unlist(map(event, pull, commented), FALSE, FALSE)) %>% 
  ggplot() +
  geom_jitter(aes(comments, reviewer_comments, 
                  col = Approved, shape = Approved), height = 0) +
  labs(y = "Reviewer's comments", x = "Comments", title = "Comments from reviewers")
```


```{r submission_acceptance2}
ord_rev <- revi_sum %>% 
  summarise(total = sum(n)) %>% 
  arrange(-total) %>% 
  pull(reviewer) %>% .[1:8]

r <- revi_sum %>% 
  mutate(Approved = ifelse(Approved == "Yes", "Approved", "Rejected"),
         reviewer = as.factor(reviewer)) %>% 
  filter(reviewer %in% ord_rev) %>% 
  mutate(reviewer = fct_drop(reviewer)) %>% 
  mutate(reviewer = fct_relevel(reviewer, !!!ord_rev)) %>% 
  ungroup() %>% 
  nest_by(Approved, reviewer_commented) %>% 
  mutate(plot_relative = list(
    ggplot(data) +
      geom_col(aes(reviewer, perc)) +
      labs(title = paste(Approved, reviewer_commented), x = element_blank(), y = "Percentage") +
      scale_y_continuous(labels = scales::percent) +
      scale_x_discrete(drop = FALSE) +
      scale_fill_brewer(type =  "qual") +
      theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) ),
    plot_abs = list(
    ggplot(data) +
      geom_col(aes(reviewer, n)) +
      labs(title = paste(Approved, reviewer_commented), x = element_blank(), y = "Issues") +
      scale_x_discrete(drop = FALSE) +
      scale_fill_brewer(type =  "qual") +
      theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1)) ))
library("patchwork")

r$plot_relative[[1]] <- r$plot_relative[[1]] + theme(axis.text.x = element_blank())
r$plot_relative[[2]] <- r$plot_relative[[2]] + theme(axis.text.x = element_blank())
r$plot_relative[[2]] <- r$plot_relative[[2]] + labs(y = element_blank())
r$plot_relative[[4]] <- r$plot_relative[[4]] + labs(y = element_blank())
ptch <- wrap_plots(r$plot_relative)
ptch  

r$plot_abs[[1]] <- r$plot_abs[[1]] + theme(axis.text.x = element_blank())
r$plot_abs[[2]] <- r$plot_abs[[2]] + theme(axis.text.x = element_blank())
r$plot_abs[[2]] <- r$plot_abs[[2]] + labs(y = element_blank())
r$plot_abs[[4]] <- r$plot_abs[[4]] + labs(y = element_blank())
ptch2 <- wrap_plots(r$plot_abs)
ptch2 
```

We can see that the percentage of approved on those issues where the reviewer commented is fairly similar and around 80% or above. 
However there is also at least a 5% of submissions that are closed despite the comments from reviewers.
Usually this has to be with unresponsiveness from the submitter:

```{r events_days}
full %>% 
  ggplot() +
  geom_line(aes(time_relative, event_n, col = id, group = id)) +
  facet_wrap(~Approved) +
  labs(title = "Events along time", subtitle = "Approved?",
       x = "Days", y = element_blank())
```

We can see that on the approved packages there are usually more events on the same time period.
So make sure to follow the advice of the reviewers and the bot and make all the errors and warnings disappear. 

```{r events_user_distribution}
p1 <- ggplot(by_issue) +
  geom_bar(aes(as.factor(diff_events))) +
  labs(y = "Issues", x = element_blank(), 
       title = "Different events in the issue")
p2 <- ggplot(by_issue) +
  geom_bar(aes(as.factor(diff_users))) +
  labs(y = element_blank(), x = element_blank(), 
       title = "Different users involved in the issue")
library("patchwork")
p1 + p2
```

While most issues have at least 8 different events they usually have 4 users involved.
Presumably the creator of the issue, bioc-issue-bot, a reviewer and someone else. 

```{r actor_event_types}
by_issue %>% 
  mutate(diff_actors = factor(diff_users, levels = 1:13)) %>% 
  ggplot() +
  geom_count(aes(diff_actors, as.factor(diff_events))) +
  labs(x = "Users", y = "Events", title = "Users involved and different events",
       size = "Issues") + 
  scale_radius() +
  scale_x_discrete(drop = FALSE) 
```

The more users involved, more different type of events are triggered.
Presumably more people get subscribed or is mentioned. 

```{r actors_events}
by_issue %>% 
  mutate(diff_actors = factor(diff_users, levels = 1:13)) %>% 
  group_by(diff_actors) %>% 
  count(events, Approved) %>% 
  ggplot() +
  geom_jitter(aes(as.factor(diff_actors), events, size = n,
                  col = Approved, shape = Approved), 
             height = 0) +
  labs(x = "Users", y = "Events", size = "Issues",
       title = "Users involved on the issues and events") +
  scale_x_discrete(drop = FALSE) + 
  scale_size(breaks = c(seq(0, 300, by = 50)))
```

As expected the more users are involved in an issue more events are produced.
We can also see the submissions that are closed by the bioc-issue-bot with few comments and users.

# Who does each action ?

We can look now at who performs what, we know there are `r nrow(by_user)` participants:

```{r who}
top_events <- 35
by_user %>%
  arrange(-actions) %>% 
  top_n(top_events, actions) %>% 
  select(actor, event) %>% 
  unnest(event) %>% 
  pivot_longer(names_to = "event", cols = created:unlabeled, values_to = "n") %>% 
  filter(n != 0) %>% 
  ggplot() + 
  geom_tile(aes(fct_reorder2(event, -n, actor), 
                fct_reorder(actor, n, .fun = sum), 
                fill = n)) +
  scale_fill_viridis_c(trans = "log10", expand = expansion()) +
  labs(title = "Events by users", y = element_blank(), x = element_blank(),
       fill = "Events") + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1, hjust = 1))
  # coord_flip()
```

Here I cut the top `r top_events` people who have triggered more than events. 
We can clearly see who are official reviewers (as seen on the previous post) because they labeled and unlabeled issues.
bioc-issue-bot is an special user that makes lots of comments and assigning reviewers to issues.
We can also see that it previously renamed the issues or unassigned reviewers.


```{r comments_plot}
comments <- full %>% 
  mutate(n = sum(event %in% "assigned"),
         assigners = list(reviewer[event %in% "assigned"]),
         unassigners = list(reviewer[event %in% "unassigned"]),
         reasigned  = any(event %in% "unassigned"),
         reviewers = list(reviewers(unlist(assigners, FALSE, FALSE), 
                                    unlist(unassigners, FALSE, FALSE))),
         reviewers_n = length(reviewers),
         creator = unique(actor[event == "created"])) %>% 
  filter(actor != "bioc-issue-bot", event == "commented", reviewers_n == 1) %>% 
  group_by(id) %>% 
  summarise(speaking = n_distinct(actor), 
            comments = n(), 
            reviewer = sum(actor == unlist(reviewer)),
            author = sum(actor == creator),
            mtmorgan = sum(actor == "mtmorgan"),
            other = comments - reviewer - author)
comments %>% 
  ggplot() +
  geom_count(aes(author, reviewer)) +
  labs(title = "Comments", x = "Authors", y = "Reviewer", size = "Issues")
```

Comments by users (excluding the bot), usually only the author, the reviewer comment, frequently mtmorgan also suggests. 

```{r comment_plot2}
comments %>% 
  filter(mtmorgan != reviewer) %>% 
  mutate(perc = mtmorgan/other) %>% 
  ggplot() +
  geom_count(aes(other, mtmorgan, col = perc)) +
  geom_abline(slope = 1, intercept = 0) +
  labs(title = "Other comments compared to mtmorgan", x = "Other", 
       size = "Issues", col = "Ratio") +
  scale_y_continuous(breaks = seq(0, 13, by = 2)) +
  scale_radius()
```

We can see that Martin Morgan has commented on almost all the submissions. 
The odd issue where there are some comments from mtmorgan but no other is the [issue 611](https://github.com/Bioconductor.org/Contributions/issue/611) where he is the reviewer and the submitter of a package.

# Bioconductor Bot

We have seen that one of the most relevant "users" is bioc-issue-bot.  
It is a bot that performs and report automatic checks on the submissions (The code can be found [here](https://github.com/Bioconductor/issue_tracker_github)). 
Let's explore what does and what does it report

```{r bioc_bot_plot}
comments <- full %>% 
  ungroup() %>% 
  filter(event == "commented")
bioc_bot <- comments %>% 
  filter(actor == "bioc-issue-bot") %>% 
  mutate(reason = case_when(
    startsWith(text, "Hi @") ~ "Received",
    startsWith(text, "Received a valid push") ~ "Valid push",
    str_detect(text, "^(\n)?Dear Package contributor,") ~ "Build result",
    startsWith(text, "A reviewer has been assigned to your package") ~ "Reviewer assigned",
    str_detect(text, "There is no repository called") ~ "Missing repository",
    str_detect(text, "Thanks for submitting your additional package") ~ "Additional package",
    str_detect(text, "has already posted ") ~ "repost",
    str_detect(text, "for an extended period of time") ~ "Closing",
    str_detect(text, "DESCRIPTION file") ~ "Unmatch",
    str_detect(text, "Your package has been approved for building") ~ "Building",
    str_detect(text, "We only start builds when the `Version`") ~ "Update version",
    str_detect(text, "a GitHub repository URL") ~ "Missing repository",
    str_detect(text, "more than one GitHub URL") ~ "Multiple repositories",
    str_detect(text, "Add SSH keys") ~ "SSH key",
    startsWith(text, "Your package has been accepted.") ~ "Accepted",
    TRUE ~ "Other"
  ))
bioc_bot %>% 
  group_by(id) %>% 
  count(reason, sort = TRUE) %>% 
  ungroup() %>% 
  ggplot() +
  geom_tile(aes(id, fct_reorder(reason, n, .fun = sum), col = n)) +
  scale_color_viridis_c(trans = "log10", expand = expansion()) +
  labs(x = "Issue", title = "bioc-issue-bot activity", 
       y = element_blank(), col = "Comments")
```

Classifying the comments reports that most of the comments are build results or that received a valid push. 
We can also see some changes on the bot, like changing the messages or reporting differently the process triggered. 
However, it also reports common problems on the submission: missing repository, unmatch between the repository name and the package name, reposting the same package, missing SSH key (needed to be able to push to Bioconductor git server), ...
We can see that most of them are related to building the packages being submitted.

Let's check if there is some differences on the comments according to if they are later accepted or not.

```{r user_events}
bm3 <- bioc_bot %>% 
  group_by(id, reason) %>% 
  summarize(n = n(), Approved = unique(Approved)) %>% 
  mutate(total = sum(n)) %>% 
  group_by(id) %>% 
  mutate(perc = n/total)

bm3 %>% 
  group_by(reason) %>% 
  filter(n_distinct(Approved) >= 2 | all(Approved == "No")) %>% 
  ggplot() +
  geom_jitter(aes(Approved, n, col = Approved, shape = Approved), height = 0) +
  facet_wrap(~reason, scales = "free", ncol = 3) +
  labs(x = element_blank(), y = "Comments", 
       title = "Diferences between accepted and non accepted issues by bioc-issue-bot comments")
```

```{r significant, eval=FALSE, include=FALSE}
bm3 %>% 
  group_by(reason) %>% 
  filter(n_distinct(Approved) >= 2 & sum(Approved == "Yes") >= 2) %>% 
  nest_by() %>% 
  mutate(t = list(t.test(n ~ Approved, data = data))) %>% 
  mutate(broom::glance(t)) %>%
  ungroup() %>% 
  mutate(adj.p.value = p.adjust(p.value)) %>% 
  filter(adj.p.value < 0.05) %>% 
  pull(reason)
```

We can see clearly differences on the behavior of the issues, some type of comments are all of the non-accepted packages.
It seems like some are not corrected. 
We can see here some common areas when submissions fail: failing to provide a valid link to the repository or many links to several repositories, or failing to comply with the guidelines about the repository name and the package name. 
Reposting the same package is also a common reason of not getting that submission approved.

The only significant are the build results, the build results, the valid push, received, unmatch between the package name and the repository, and the update version. 



```{r common_feedback}
build_related <- c("Build result", "Building", "Valid push", "Received", 
                   "Update version")

bm_com <- bioc_bot %>% 
  group_by(id) %>% 
  summarise(builds = sum(reason %in% build_related), 
            total = n(),
            diff = total - builds, 
            Approved = unique(Approved)) 
bm_com %>%
  ggplot() +
  geom_count(aes(total, builds, col = Approved, shape = Approved)) +
  facet_wrap(~ Approved) +
  labs(x = "All comments", title = "bioc-issue-bot comments",
       y = "Build related", size = "Issues")
```

We can see, (and I expected so) that comments of bioc-issue-bot are driven by the build system.

```{r bot_comments_approve}
# t.test(diff ~ Approved, data = ungroup(bm_com))
bm_com %>% 
  count(diff, Approved) %>% 
  ggplot() +
  geom_tile(aes(Approved, as.factor(diff), fill = n)) +
  # geom_jitter(aes(Approved, diff, col = Approved), height = 0) +
  # geom_violin(aes(Approved, diff, col = Approved), alpha = 0) +
  labs(x = element_blank(), 
       title = "bioc-issue-bot comments not related to builds", 
       y = "Comments not related to builds", fill = "Issues")
```

But the other comments are more frequent among the not approved packages, mainly errors and other automatically detected problems. 

Aside from the bot, other users might comment on issues too:

```{r comments_issues}
com_is <- full %>% 
  group_by(id) %>% 
  mutate(submitter = unique(actor[event == "created"])) %>% 
  mutate(assigners = list(reviewer[event %in% "assigned"]),
         unassigners = list(reviewer[event %in% "unassigned"]),
         reviewers = list(setdiff(unlist(assigners, FALSE, FALSE), 
                                  unlist(unassigners, FALSE, FALSE))),
         commenter = case_when(
           actor %in% unlist(reviewers) ~ "Reviewer",
           actor %in% submitter ~ "Author",
           TRUE ~ "Other")
  ) %>% 
  filter(actor != "bioc-issue-bot" & event == "commented") %>% 
  ungroup()
com_is_w <- com_is %>% 
  group_by(id) %>% 
  count(commenter) %>% 
  pivot_wider(names_from = commenter, values_from = n, values_fill = 0) %>% 
  ungroup()
  
ra <- com_is_w %>% 
  group_by(Author, Reviewer) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = 1) +
  geom_point(aes(Author, Reviewer, col = n)) +
  scale_color_continuous(limits = c(1, 50)) +
  guides(col = FALSE)
ro <- com_is_w %>% 
  group_by(Other, Reviewer) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = -1) +
  geom_point(aes(Reviewer, Other, col = n)) +
  scale_y_continuous(position = "right") +
  scale_x_continuous(trans = "reverse") +
  labs(y = element_blank()) +
  scale_color_continuous(limits = c(1, 50)) +
  guides(col = FALSE)
oa <- com_is_w %>% 
  group_by(Author, Other) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = 1) +
  geom_point(aes(Author, Other, col = n)) +
  scale_color_continuous(limits = c(1, 50)) +
  labs(col = "Issues")
  # guides(col = FALSE)
ra /(ro + oa ) +
  plot_annotation(title = "Comments on submissions by users",
                  tag_levels = "i") &
  plot_layout(guides = "collect") 
```

In some issues reviewers comment more than authors, while on some there are more comments from authors than reviewers. 
Surprisingly, in some issues there are more comments from other users than authors or reviewers.

```{r comments_approved}
com_is_w <- com_is %>% 
  group_by(id, Approved) %>% 
  count(commenter) %>% 
  pivot_wider(names_from = commenter, values_from = n, values_fill = 0) %>% 
  ungroup()
  
a <- com_is_w %>% 
  group_by(Author, Reviewer, Approved) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = 1) +
  geom_point(aes(Author, Reviewer, col = n)) +
  scale_color_continuous(limits = c(1, 50)) +
  labs(col = "Issues") +
  facet_wrap(~Approved)
b <- com_is_w %>% 
  group_by(Other, Reviewer, Approved) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = 1) +
  geom_point(aes(Reviewer, Other, col = n)) +
  scale_color_continuous(limits = c(1, 50)) +
  facet_wrap(~Approved) +
  labs(col = "Issues")
d <- com_is_w %>% 
  group_by(Author, Other, Approved) %>% 
  count(sort = TRUE) %>% 
  ggplot() +
  geom_abline(slope = 1) +
  geom_point(aes(Author, Other, col = n)) +
  scale_color_continuous(limits = c(1, 50)) +
  facet_wrap(~Approved) +
  labs(col = "Issues")
a + b + d + plot_layout(ncol = 1,
                        guides = "collect")  +
  plot_annotation(title = "Comments on submissions by users",
                  subtitle = "Separated by if approved or not")
```

Usually packages not approved have less comments from authors, reviewers and other users.

About the time to get feedback we have previously seen that most of the issues were fast.
However it included automatic actions from the bot, so let's check again without the automatic events.

```{r delays}

closed_c <- full %>% 
  mutate(comment_n = cumsum(event == "commented" & actor != "bioc-issue-bot")) %>% 
  filter(event == "closed") %>% 
  filter(event_n == max(event_n)) %>% 
  select(id, time_relative, comment_n, event_n, Approved)

full %>% 
  filter(event %in% c("commented", "created") & actor != "bioc-issue-bot") %>% 
  mutate(comment_n = cumsum(event == "commented" & actor != "bioc-issue-bot")) %>% 
  ggplot() +
  geom_point(aes(time_relative, comment_n, col = id),  data = closed_c, shape = "square") +
  geom_line(aes(time_relative, comment_n, group = id, col = id)) +
  facet_wrap(~Approved, scales = "free") +
  guides(col = FALSE) + 
  labs(x = "Since creation of the issue (days)", y = "Comments", title = "Comments on issues")
```

Here the squares indicate when a issue is closed, and we can see most comments are before the issues are closed.

```{r closing}
closed_c <- mutate(closed_c, Closed = TRUE)
aftr <- full %>% 
  filter(event %in% c("commented", "created") & actor != "bioc-issue-bot") %>% 
  mutate(comment_n = cumsum(event == "commented" & actor != "bioc-issue-bot"),
         Closed = FALSE) %>% 
  select(id, time_relative, comment_n, event_n, Approved, Closed) %>% 
  rbind(closed_c) %>% 
  group_by(id) %>% 
  mutate(Closed = event_n > ifelse(any(Closed), event_n[Closed], Inf))
aftr %>% 
  group_by(id, Approved) %>% 
  count(Closed) %>% 
  filter(Closed) %>% 
  ggplot() + 
  geom_jitter(aes(Approved, n, col = Approved, shape = Approved), height = 0) +
  labs(x = element_blank(), y = "Comments", 
       title = "Comments after being closed",
       size = "Issues")
```

And there doesn't seem to be any difference between approved and not approved packages.

I would have expected more comments after closing an issue in the not approved submissions.
This might indicate that the discussion happens before and/or that the process after closing the issue is not clear enough. 



Let's see how much time does it take to start the review and the time till the reviewer comments:

```{r successful_build}
full %>% 
  summarise(success_build = any(event == "labeled" & label == "OK"),
            Approved = unique(Approved)) %>% 
  ungroup() %>% 
  count(success_build, Approved, sort = TRUE) %>% 
  mutate(success_build = ifelse(success_build, "Yes", "No"))%>% 
  arrange(Approved, -n) %>% 
  knitr::kable(col.names = c("Successful build?", "Approved?", "Submissions"))
```

We can see that most not approved packages do not have a successful build. 

```{r trans_builds}
logic_nth <- function(x, n){
  y <- rep(FALSE, length(!!x))
  z <- which(!!x)
  y[z[seq_len(n)]] <- TRUE
  y
}
builds <- full %>% 
  mutate(assigners = list(reviewer[event %in% "assigned"]),
            unassigners = list(reviewer[event %in% "unassigned"]),
            reviewers = list(reviewers(unlist(assigners, FALSE, FALSE), 
                                    unlist(unassigners, FALSE, FALSE))),
         comment = event == "commented"
         ) %>% 
  filter((event == "labeled" & label == "OK") |
           (comment & actor %in% unlist(reviewers))) %>% 
  arrange(id, event_n) %>% 
  mutate(keel = logic_nth(event == "labeled", 1),
         keec = event == "commented",
         k = any(keel),
         k2 = ifelse(any(keel), event_n >= event_n[keel], FALSE),
         k3 = keel | (keec  & k2),
         k4 = logic_nth(k3, 2)) %>% 
  filter(k4)
builds %>% 
  ggplot() +
  geom_point(aes(time_relative, id, col = event)) +
  facet_wrap(~Approved, ncol = 2) +
  labs(x = "Days since submission",
       y = "Issue",
       title = "First successful build and comment of the reviewer after",
       subtitle = "Submission approved?",
       col = "Event")
```

An overview of the submissions, when was the first successful build and when was the first comment of the reviewer after the successful build. 

```{r time_comment}
bc <- builds %>% 
  select(id, time_relative, event, Approved) %>% 
  pivot_wider(names_from = event, values_from = time_relative, values_fill = NA)
bc <- bc %>% 
  # filter(!is.na(labeled) & !is.na(commented)) %>% 
  mutate(td = commented-labeled)
bc %>% 
  filter(!is.na(labeled) & !is.na(commented)) %>% 
  ggplot() +
  geom_linerange(aes(y = id, xmin = labeled, xmax = commented)) +
  facet_wrap(~Approved, ncol = 2, scales = "free") +
  labs(title = "Time between successful build and comment from the reviewer",
       x = "Days since submission", y = "Issue", 
       subtitle = "Submission approved?")
```

Usually it takes close to `r round(median(bc$labeled, na.rm = TRUE))` days to have the first successful build on Bioconductor (if there is any as we have seen). 

After it it takes close to `r round(median(bc$td, na.rm = TRUE))` days to the reviewer to comment.
This comment might be the review of the package, as it is only done after the submissions passes all the checks.

```{r td_plot}
p1 <- bc %>% 
  ggplot() +
  geom_histogram(aes(labeled), binwidth = 1) +
  facet_wrap(~Approved) +
  labs(subtitle = "Submission approved?", 
       title = "Days between submission and the first successful build",
       x = "Days", y = "Issues")
p1
p1 +
  coord_cartesian(xlim = c(0, 7)) +
  labs(caption = "A zoom to the first week")
bc %>% 
  ggplot() +
  geom_histogram(aes(td)) +
  facet_wrap(~Approved) +
  labs(subtitle = "Submission approved?", 
       title = "Days between successful build and comment from reviwers",
       x = "days", y = "Issues")
```

Usually the packages that get approved take a bit longer to be commented. 

```{r}
bc %>% 
  group_by(Approved) %>% 
  summarize(across(labeled:td, function(x){round(median(x, na.rm = TRUE))})) %>% 
  knitr::kable(col.names = c("Approved", "Days to succcessful build",
                      "Days to reviewer comment after build",
                      "Days between build and reviewer comment"))
```


# Conclusions

Most of the problems with the submissions are formal and automatically detected by the bot.
Next come problems from the package itself not passing the checks performed on Bioconductor.
So if you want to have your package included make sure that the package builds on Bioconductor and respond fast to the feedback provided by the bot. 

### Reproducibility

<details>
```{r reproducibility, echo = FALSE}
## Reproducibility info
options(width = 120)
sessioninfo::session_info()
```
</details>
